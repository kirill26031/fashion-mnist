{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate_dataset = FashionMNIST(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = FashionMNIST(root='data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train = pd.read_csv('data/fashion-mnist_train.csv')\n",
    "csv_test = pd.read_csv('data/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classes:\n",
    "classes = train_and_validate_dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataframe is class (from 0 to 9) and 28*28 monohrome pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount of dataframes in train, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 60000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size:\", len(csv_train))\n",
    "print(\"Test dataset size:\", len(csv_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(dataset: FashionMNIST, index: int):\n",
    "    figure = plt.figure(figsize = (5,5))\n",
    "    image, label = dataset[index]\n",
    "    plt.title(dataset.classes[label])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Example of image\n",
    "show_image(train_and_validate_dataset, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_distribution(frames: pd.DataFrame, classes: list[str]):\n",
    "    value_counts = frames['label'].value_counts()\n",
    "    total_amount = len(frames)\n",
    "    for i in range(len(value_counts)):\n",
    "        label = classes[value_counts.index[i]]\n",
    "        amount = value_counts.values[i]\n",
    "        percentage = amount * 100 / total_amount\n",
    "        print(\"#{} {:<15s}:   {} or {}%\".format(value_counts.index[i], label, amount, percentage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set class distribution\n",
      "#2 Pullover       :   6000 or 10.0%\n",
      "#9 Ankle boot     :   6000 or 10.0%\n",
      "#6 Shirt          :   6000 or 10.0%\n",
      "#0 T-shirt/top    :   6000 or 10.0%\n",
      "#3 Dress          :   6000 or 10.0%\n",
      "#4 Coat           :   6000 or 10.0%\n",
      "#5 Sandal         :   6000 or 10.0%\n",
      "#8 Bag            :   6000 or 10.0%\n",
      "#7 Sneaker        :   6000 or 10.0%\n",
      "#1 Trouser        :   6000 or 10.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set class distribution\")\n",
    "get_classes_distribution(csv_train, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set class distribution\n",
      "#0 T-shirt/top    :   1000 or 10.0%\n",
      "#1 Trouser        :   1000 or 10.0%\n",
      "#2 Pullover       :   1000 or 10.0%\n",
      "#3 Dress          :   1000 or 10.0%\n",
      "#8 Bag            :   1000 or 10.0%\n",
      "#6 Shirt          :   1000 or 10.0%\n",
      "#5 Sandal         :   1000 or 10.0%\n",
      "#4 Coat           :   1000 or 10.0%\n",
      "#7 Sneaker        :   1000 or 10.0%\n",
      "#9 Ankle boot     :   1000 or 10.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set class distribution\")\n",
    "get_classes_distribution(csv_test, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_conv_layers(conv1_out, conv1_kernel_size, conv2_out, conv2_kernel_size):\n",
    "    conv2_in = conv1_out \n",
    "    return nn.ParameterList([\n",
    "        nn.Conv2d(in_channels=1, out_channels=conv1_out, kernel_size=conv1_kernel_size),\n",
    "        nn.Conv2d(in_channels=conv2_in, out_channels=conv2_out, kernel_size=conv2_kernel_size)\n",
    "    ])\n",
    "\n",
    "def construct_fc_layers(after_conv_size, fc1_out, fc2_out, classes_amount):\n",
    "    return nn.ParameterList([\n",
    "        nn.Linear(in_features=after_conv_size, out_features=fc1_out),\n",
    "        nn.Linear(in_features=fc1_out, out_features=fc2_out),\n",
    "        nn.Linear(in_features=fc2_out, out_features=classes_amount)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module): \n",
    "    def __init__(self, conv1_out, conv1_kernel_size, conv2_out, conv2_kernel_size, fc1_out, fc2_out, image_size = 28, classes_amount = 10):\n",
    "        super().__init__()\n",
    "        self.conv_layers = construct_conv_layers(conv1_out, conv1_kernel_size, conv2_out, conv2_kernel_size)\n",
    "        self.activation = nn.functional.relu\n",
    "        self.after_conv_size = (image_size - 4)**2 * conv2_out\n",
    "        self.pool = nn.functional.adaptive_avg_pool2d\n",
    "        self.fully_connected_layers = construct_fc_layers(self.after_conv_size, fc1_out, fc2_out, classes_amount)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.conv_layers)):\n",
    "            conv_l = self.conv_layers[i]\n",
    "            # print(x.shape)\n",
    "            x = conv_l(x)\n",
    "            # print(x.shape)\n",
    "            x = self.activation(x)\n",
    "            # print(x.shape)\n",
    "            x = self.pool(x, output_size=x.shape[2])\n",
    "            # print(x.shape)\n",
    "        \n",
    "        x = x.view(-1, self.after_conv_size)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        for i in range(len(self.fully_connected_layers)):\n",
    "            fc_l = self.fully_connected_layers[i]\n",
    "            x = fc_l(x)\n",
    "            # print(x.shape)\n",
    "            x = self.activation(x)\n",
    "            # print(x.shape)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, loader, func):\n",
    "        self.loader = loader\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in iter(self.loader):\n",
    "            yield self.func(*batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def to_device(X, y):\n",
    "    return X.to(device), y.to(device, dtype=torch.int64)\n",
    "\n",
    "train_data, validate_data = random_split(dataset=train_and_validate_dataset, lengths=[0.8, 0.2])\n",
    "test_data = test_dataset\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = WrappedDataLoader(DataLoader(train_data, batch_size = batch_size), to_device)\n",
    "validate_loader = WrappedDataLoader(DataLoader(validate_data, batch_size = batch_size), to_device)\n",
    "test_loader = WrappedDataLoader(DataLoader(test_data, batch_size = batch_size), to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, loss_func, X, y, optimizer=None):\n",
    "    loss_ = loss_func(model(X), y)\n",
    "    if optimizer is not None:\n",
    "      loss_.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "    return loss_.item(), len(X)\n",
    "\n",
    "def validate(model, loss_func, X, y):\n",
    "    output = model(X)\n",
    "    loss_ = loss_func(output, y)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    correct = pred == y.view(*pred.shape)\n",
    "\n",
    "    return loss_.item(), torch.sum(correct).item(), len(X)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        correct = 0\n",
    "        length = 0\n",
    "\n",
    "        for x, y in loader:\n",
    "            loss_, correct_, len_ = validate(model, nn.CrossEntropyLoss(), x, y)\n",
    "            losses.append(np.multiply(loss_, len_))\n",
    "            correct += correct_\n",
    "            length += len_\n",
    "        test_loss = np.sum(losses) / length\n",
    "        test_accuracy = correct / length * 100\n",
    "\n",
    "        print(f\"Test loss: {test_loss:.5f}\\t\"\n",
    "          f\"Test accuracy: {test_accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: MLP, epochs: int, optimizer: torch.optim.Optimizer, patience = 10, model_name='model'): \n",
    "    loss_min = np.Inf\n",
    "    wait = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        losses = []\n",
    "        length = 0\n",
    "        for tr_x, tr_y in train_loader:\n",
    "            loss_, len_ = loss(model, nn.CrossEntropyLoss(), tr_x, tr_y, optimizer)\n",
    "            losses.append(np.multiply(loss_, len_))\n",
    "            length += len_\n",
    "        train_loss = np.sum(losses) / length\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            losses = []\n",
    "            correct = 0\n",
    "            length = 0\n",
    "            for v_x, v_y in validate_loader:\n",
    "                loss_, correct_, len_ = validate(model=model, loss_func=nn.CrossEntropyLoss(), X=v_x, y=v_y)\n",
    "                losses.append(np.multiply(loss_, len_))\n",
    "                correct += correct_\n",
    "                length += len_\n",
    "            valid_loss = sum(losses) / length\n",
    "            valid_accuracy = correct / length * 100\n",
    "\n",
    "            print(f\"\\nepoch: {epoch+1:3}, loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, valid accuracy: {valid_accuracy:.3f}%\")\n",
    "\n",
    "\n",
    "            # Save model if validation loss has decreased\n",
    "            if valid_loss <= loss_min:\n",
    "                print(f\"Validation loss decreased ({loss_min:.6f} --> {valid_loss:.6f}). Saving model...\")\n",
    "                torch.save(model.state_dict(), model_name + '.pt')\n",
    "                loss_min = valid_loss\n",
    "                wait = 0\n",
    "            # Early stopping\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= patience:\n",
    "                    print(f\"Terminated Training for Early Stopping at Epoch {epoch+1}\")\n",
    "                    return\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_328\\984606344.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  check_point = torch.load(model_name + '.pt', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.33802\tTest accruacy: 87.930%\n"
     ]
    }
   ],
   "source": [
    "model = MLP(8, 3, 8, 3, 12, 12).to(device=device)\n",
    "model_name = 'first_model'\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# train(model, 100, optimizer=optimizer, model_name=model_name)\n",
    "\n",
    "check_point = torch.load(model_name + '.pt', map_location=device)\n",
    "model.load_state_dict(check_point)\n",
    "evaluate(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
